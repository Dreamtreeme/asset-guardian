from services.collector import collector
from services.engine.finance import analyze_long_term
from services.engine.technical import analyze_mid_term, analyze_short_term
from services.llm import llm_service
from fastapi import APIRouter, Depends
from sqlalchemy.orm import Session
from api import deps
from schemas.analysis import AnalysisCreate, AnalysisOut
import logging

logger = logging.getLogger(__name__)

router = APIRouter()

@router.post("/", response_model=AnalysisOut)
async def create_analysis(
    *,
    db: Session = Depends(deps.get_db),
    analysis_in: AnalysisCreate
):
    """
    ë¶„ì„ ì‹¤í–‰ API
    """
    # TODO: DBì— ê¸°ë¡í•˜ê³  ë¹„ë™ê¸° ì‘ì—… ìƒì„±
    # ì„ì‹œë¡œ ê³ ì • ID ë°˜í™˜ (ì‹¤ì œë¡œëŠ” DBì—ì„œ ìƒì„±ëœ ID ì‚¬ìš©)
    return {"id": 1, "status": "pending", "symbol": analysis_in.symbol}

@router.get("/{analysis_id}", response_model=AnalysisOut)
async def get_analysis(
    *,
    db: Session = Depends(deps.get_db),
    analysis_id: int,
    symbol: str  # ì¿ ë¦¬ íŒŒë¼ë¯¸í„°ë¡œ symbol í•„ìˆ˜ ì…ë ¥
):
    """
    ë¶„ì„ ìƒíƒœ ì¡°íšŒ API
    """
    logger.info(f"ğŸ” [API] {symbol} ë¶„ì„ ê²°ê³¼ ì¡°íšŒ ìš”ì²­ ìˆ˜ì‹  (ID: {analysis_id})")
    print(f"ğŸ” [API] {symbol} ìš”ì²­ ìˆ˜ì‹  í™•ì¸", flush=True)
    # 1. ë°ì´í„° ìˆ˜ì§‘
    td = await collector.fetch_ticker_data(symbol)
    
    # 2. ì—”ì§„ ì‹¤í–‰
    long_res = analyze_long_term(td)
    mid_res = analyze_mid_term(td)
    short_res = analyze_short_term(td)
    
    # 3. ì—ëŸ¬ ì²˜ë¦¬: ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°
    if "error" in long_res or "error" in mid_res or "error" in short_res:
        error_msg = long_res.get("error") or mid_res.get("error") or short_res.get("error")
        return {
            "id": analysis_id,
            "status": "failed",
            "symbol": symbol,
            "long_term": {"message": f"ì—ëŸ¬: {error_msg}"},
            "mid_term": {"message": "ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨"},
            "short_term": {"message": "ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨"},
            "llm_output": {
                "investment_rating": "ë¶„ì„ ë¶ˆê°€",
                "current_price": 0,
                "key_thesis": "ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨",
                "primary_risk": "ì‹œìŠ¤í…œ ì˜¤ë¥˜",
                "report_markdown": f"ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨ë¡œ ë³´ê³ ì„œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì›ì¸: {error_msg})"
            }
        }

    # 4. LLM ë³´ê³ ì„œ ìƒì„±
    company_name = td.info.get("longName") or td.info.get("shortName") or symbol
    
    # ìºì‹œ ë˜ëŠ” LLM í˜¸ì¶œ
    from datetime import datetime, date
    from models.report_cache import ReportCache
    from services.preprocessing import (
        preprocess_financial_data,
        preprocess_technical_data,
        preprocess_short_term_data
    )
    
    llm_output = None
    today = date.today()

    
    # ìºì‹œ í™•ì¸
    try:
        cached_report = db.query(ReportCache).filter(
            ReportCache.symbol == symbol,
            ReportCache.report_date >= datetime.combine(today, datetime.min.time()),
            ReportCache.report_date < datetime.combine(today, datetime.max.time())
        ).first()
        
        if cached_report:
            logger.info(f"ğŸ’¾ [API] {symbol} ìºì‹œëœ ë³´ê³ ì„œ ë°œê²¬! (ìºì‹œ ë°ì´í„° ì‚¬ìš©)")
            print(f"ğŸ’¾ [API] {symbol} ìºì‹œ ì ì¤‘", flush=True)
            llm_output = cached_report.llm_output
        else:
            logger.info(f"ğŸ†• [API] {symbol} ìºì‹œ ì—†ìŒ. ì‹ ê·œ LLM ë¶„ì„ ì§„í–‰...")
            print(f"ğŸ†• [API] {symbol} LLM ë¶„ì„ ì‹œì‘", flush=True)
    except Exception as e:
        logger.error(f"âš ï¸ [API] ìºì‹œ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œí•˜ê³  ì§„í–‰): {e}")
        pass

    # ë¦¬ìŠ¤í¬ ì§€í‘œ ê³„ì‚°
    import numpy as np
    var_5_pct = 0
    volatility = 0
    if hasattr(td, 'px_10y') and not td.px_10y.empty:
        daily_returns = td.px_10y["Close"].pct_change().dropna()
        var_5_pct = float(daily_returns.quantile(0.05)) if len(daily_returns) > 0 else 0
        volatility = float(daily_returns.std() * np.sqrt(252)) if len(daily_returns) > 0 else 0

    # LLM í˜¸ì¶œ ë° ìºì‹œ ì €ì¥
    if llm_output is None:
        long_term_data = preprocess_financial_data(long_res)
        # ë¦¬ìŠ¤í¬ ì§€í‘œ ì¶”ê°€ (LLM ì°¸ê³ ìš©)
        long_term_data["risk_metrics_raw"] = {
            "var_5_pct": var_5_pct,
            "volatility": volatility,
            "max_drawdown_5y": long_res.get("evidence", {}).get("ì¥ê¸°ì¶”ì„¸", {}).get("ìµœê·¼5ë…„_MDD", 0)
        }

        analysis_data_preprocessed = {
            "symbol": symbol,
            "company_name": company_name,
            "long_term": long_term_data,
            "mid_term": preprocess_technical_data(mid_res),
            "short_term": preprocess_short_term_data(short_res)
        }
        
        llm_output = await llm_service.generate_report(analysis_data_preprocessed)

        # ìºì‹œ ì €ì¥ (ì„±ê³µí•œ ë¶„ì„ ê²°ê³¼ë§Œ ì €ì¥)
        if llm_output.get("is_success"):
            try:
                db.add(ReportCache(
                    symbol=symbol,
                    report_date=datetime.now(),
                    llm_output=llm_output
                ))
                db.commit()
                logger.info(f"âœ… [API] {symbol} LLM ë³´ê³ ì„œ ìºì‹œ ì €ì¥ ì™„ë£Œ")
                print(f"âœ… [API] {symbol} ìºì‹œ ì €ì¥ ì„±ê³µ", flush=True)
            except Exception as save_err:
                db.rollback()
                logger.error(f"âŒ [API] {symbol} ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {save_err}")
                print(f"âŒ [API] {symbol} ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {save_err}", flush=True)
        else:
            logger.warning(f"âš ï¸ [API] {symbol} ë¶„ì„ ê²°ê³¼ê°€ ì •ìƒì´ ì•„ë‹ˆì–´ì„œ ìºì‹œë¥¼ ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            print(f"âš ï¸ [API] {symbol} ë¶„ì„ ì‹¤íŒ¨ë¡œ ìºì‹œ ì €ì¥ ê±´ë„ˆëœ€", flush=True)
    

    
    # ì‘ë‹µ ë°ì´í„° êµ¬ì¡°í™” (ê°€ë…ì„± ê°œì„ )
    long_evidence = long_res.get("evidence", {})
    long_trends = long_evidence.get("ì¬ë¬´ì¶”ì„¸", {})
    long_valuation = long_evidence.get("ë°¸ë¥˜ì—ì´ì…˜", {})
    
    mid_evidence = mid_res.get("evidence", {})
    
    short_evidence = short_res.get("evidence", {})
    short_pivot = short_evidence.get("ê¸ˆì¼í”¼ë´‡", {})
    short_yesterday = short_evidence.get("ì „ì¼", {})
    
    # ìƒë‹¨ì—ì„œ ì´ë¯¸ ë¦¬ìŠ¤í¬ ì§€í‘œ ê³„ì‚°ë¨
    
    return {
        "id": analysis_id,
        "status": "completed",
        "symbol": symbol,
        "company_name": company_name,
        "long_term": {
            # ì°¨íŠ¸ìš© ì¬ë¬´ ì¶”ì„¸ ë°ì´í„°
            "financial_trends": long_trends,
            
            # ì°¨íŠ¸ìš© ê°€ê²© ë°ì´í„° (ìµœê·¼ 1ë…„)
            "price_history": {
                "dates": [str(d) for d in td.px_10y.index[-252:].tolist()],
                "close": td.px_10y["Close"].iloc[-252:].tolist(),
                "ma200": td.px_10y["Close"].rolling(window=200).mean().iloc[-252:].tolist(),
                "ma300": td.px_10y["Close"].rolling(window=300).mean().iloc[-252:].tolist()
            } if hasattr(td, 'px_10y') and not td.px_10y.empty else {},
            
            # ë¦¬ìŠ¤í¬ ì§€í‘œ
            "risk_metrics": {
                "max_drawdown_5y": long_evidence.get("ì¥ê¸°ì¶”ì„¸", {}).get("ìµœê·¼5ë…„_MDD", 0),
                "var_5_pct": var_5_pct,
                "volatility": volatility
            },
            
            # ë°¸ë¥˜ì—ì´ì…˜ ì§€í‘œ
            "peg_ratio": long_valuation.get("trailingPEG", 0),
            "roe": long_valuation.get("ROE", 0),
            "current_ratio": long_valuation.get("currentRatio", 0)
        },
        "mid_term": {
            "rsi_value": mid_evidence.get("RSI", 0)
        },
        "short_term": {
            "current_price": short_pivot.get("Pivot", 0) # í˜„ì¬ê°€ ë°±ì—…ìš©
        },
        "llm_output": llm_output
    }

