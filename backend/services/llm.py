import anthropic
import json
from core.config import settings

RESEARCH_REPORT_PROMPT = """
ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ ê¸ˆìœµ ìì‚° ë¶„ì„ê°€(Senior Equity Analyst)ì…ë‹ˆë‹¤.
ì œê³µëœ ì¢…ëª© ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ì ì´ê³  ì‹ ë¢°ë„ ë†’ì€ ë¦¬ì„œì¹˜ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì‹­ì‹œì˜¤.

## í•µì‹¬ ìš”êµ¬ì‚¬í•­
- **í†¤ ì•¤ ë§¤ë„ˆ**: ê·¹ë„ì˜ ì ˆì œë¯¸, ì •ëŸ‰ì  ê¸°ë°˜, ìˆ˜ì‹ì–´ ë°°ì œ (ì˜ˆ: 'ê°•ë ¥í•œ', 'ëª…í™•íˆ', 'ì¶©ì‹¤íˆ' ë“± ì‚¬ìš© ê¸ˆì§€)
- **ì–¸ì–´**: í•œêµ­ì–´ (íˆ¬ìì˜ê²¬ì€ ë§¤ìˆ˜/ë³´ìœ /ë¹„ì¤‘ì¶•ì†Œ ëª…ì‹œ)
- **ì¤‘ë³µ ì—„ê¸ˆ**: ëª¨ë“  í•„ë“œì—ì„œ ë™ì¼í•œ ìˆ˜ì¹˜ë¥¼ ë°˜ë³µ ì–¸ê¸‰í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
- **ê°„ê²°ì„±**: ìˆ˜ì¹˜ ë‚˜ì—´ë³´ë‹¤ëŠ” ê·¸ ìˆ˜ì¹˜ê°€ ì˜ë¯¸í•˜ëŠ” 'ê²°ë¡ 'ë§Œ í•œ ë¬¸ì¥ìœ¼ë¡œ ì„œìˆ í•˜ì‹­ì‹œì˜¤.

## ì„¹ì…˜ë³„ ì‘ì„± ê°€ì´ë“œ (JSON ê° í•„ë“œ)
1. `executive_summary`: ì „ì²´ ë¶„ì„ì˜ ìµœì¢… ê²°ë¡ . **ìµœëŒ€ 3ë¬¸ì¥**ìœ¼ë¡œ ì œí•œí•˜ë©°, ê°œë³„ ë¶„ì„ ë‚´ìš©ì„ ìš”ì•½í•˜ì§€ ë§ê³  'ìµœì¢… íˆ¬ì íŒë‹¨'ë§Œ ì„œìˆ í•˜ì‹­ì‹œì˜¤.
2. `fundamental_analysis`: ì‹¤ì  ì¶”ì„¸ì™€ ìˆ˜ìµì„± ë°©í–¥ì„±. ìˆ˜ì¹˜ ë‚˜ì—´ ëŒ€ì‹  'ì„±ì¥ì„± ì—¬ë¶€'ë§Œ ì„œìˆ í•˜ì‹­ì‹œì˜¤.
3. `valuation_analysis`: ì£¼ê°€ ë§¤ë ¥ë„ì™€ ì¬ë¬´ ê±´ì „ì„±. PEGì™€ ì•ˆì •ì„± ì§€í‘œ ê¸°ë°˜ì˜ ê°€ì¹˜ íŒë‹¨ë§Œ ì„œìˆ í•˜ì‹­ì‹œì˜¤.
4. `technical_analysis`: RSI ë° ì´í‰ì„ ì´ ì‹œì‚¬í•˜ëŠ” í˜„ì¬ì˜ 'ë§¤ë§¤ ìœ„ì¹˜'ì™€ 'ë‹¨ê¸° ë°©í–¥ì„±'ë§Œ ì„œìˆ í•˜ì‹­ì‹œì˜¤.
5. `risk_analysis`: í˜„ì¬ ê°€ì¥ ê²½ê³„í•´ì•¼ í•  í•µì‹¬ ë¦¬ìŠ¤í¬ 1ê°€ì§€ë§Œ ì„œìˆ í•˜ì‹­ì‹œì˜¤.

## ì˜ˆì‹œ ë‹µë³€ (JSON í˜•ì‹)
```json
{
  "investment_rating": "ë³´ìœ  (HOLD)",
  "current_price": 72500,
  "key_thesis": "ì˜ì—…ì´ìµë¥  ë°˜ë“±ì— ë”°ë¥¸ ìˆ˜ìµì„± íšŒë³µ ë° 200ì¼ ì´í‰ì„ ì˜ ì§€ì§€ë ¥ í™•ì¸",
  "primary_risk": "RSI 85 ìˆ˜ì¤€ì˜ ë‹¨ê¸° ê³¼ë§¤ìˆ˜ ë¦¬ìŠ¤í¬ ë° ë†’ì€ ë³€ë™ì„±",
  "executive_summary": "ìˆ˜ìµì„± íšŒë³µì„¸ëŠ” ëšœë ·í•˜ë‚˜ ê¸°ìˆ ì  ê³¼ì¤‘ êµ¬ê°„ì— ì§„ì…í–ˆìŠµë‹ˆë‹¤. ì‹ ê·œ ë§¤ìˆ˜ë³´ë‹¤ëŠ” ì¡°ì • ì‹œ ë¹„ì¤‘ í™•ëŒ€ë¥¼ ê¶Œê³ í•˜ëŠ” ë³´ìœ  ê´€ì ì´ ì ì ˆí•©ë‹ˆë‹¤.",
  "fundamental_analysis": "ë§¤ì¶œ ë°˜ë“±ê³¼ ì˜ì—…ì´ìµë¥ ì˜ Vì íšŒë³µìœ¼ë¡œ ì‹¤ì  í„´ì–´ë¼ìš´ë“œ êµ­ë©´ì— ì§„ì…í•œ ê²ƒìœ¼ë¡œ ë¶„ì„ë©ë‹ˆë‹¤.",
  "valuation_analysis": "PEG 0.85ë¡œ ì„±ì¥ì„± ëŒ€ë¹„ ì£¼ê°€ ë§¤ë ¥ì€ ë†’ìœ¼ë‚˜ ë¶€ì±„ë¹„ìœ¨ ê°ì†Œ ì—¬ë¶€ì— ëŒ€í•œ ëª¨ë‹ˆí„°ë§ì´ í•„ìš”í•©ë‹ˆë‹¤.",
  "technical_analysis": "200ì¼ì„  ì§€ì§€ë¡œ ì¥ê¸° ìƒìŠ¹ ë™ë ¥ì€ ìœ íš¨í•˜ë‚˜, ê³¼ë§¤ìˆ˜ ì‹ í˜¸ë¡œ ì¸í•œ ë‹¨ê¸° í‰ê·  íšŒê·€ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.",
  "risk_analysis": "ê³¼ê±° 5ë…„ MDD -45% ì „ë¡€ë¥¼ ê³ ë ¤í•  ë•Œ í•˜ë½ì¥ ì „í™˜ ì‹œì˜ ë†’ì€ ë³€ë™ì„±ì„ ê²½ê³„í•´ì•¼ í•©ë‹ˆë‹¤."
}
```

## ì¤‘ìš” ê·œì¹™
- ë°˜ë“œì‹œ ```json ... ``` ì½”ë“œ ë¸”ë¡ìœ¼ë¡œ ê°ì‹¸ì‹­ì‹œì˜¤.
- ë„ì–´ì“°ê¸°ë¥¼ ì •í™•íˆ í•˜ë©°, ë‹¨ì–´ ì‚¬ì´ì— ë¶ˆí•„ìš”í•œ ê³µë°±ì„ ë„£ì§€ ë§ˆì‹­ì‹œì˜¤.
- **`conclusion`, `report_markdown` í•„ë“œëŠ” ì ˆëŒ€ ìƒì„±í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.** (ì¤‘ë³µ ë°©ì§€)
- **ìˆ˜ì‹ì–´ë¥¼ ë°°ì œí•˜ê³  ê±´ì¡°í•œ ì‚¬ì‹¤ ìœ„ì£¼ë¡œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.**
"""

import logging
logger = logging.getLogger(__name__)

class LLMService:
    def __init__(self):
        self.client = anthropic.AsyncAnthropic(api_key=settings.ANTHROPIC_API_KEY)

    async def generate_report(self, analysis_data: dict) -> dict:
        symbol = analysis_data.get("symbol")
        company_name = analysis_data.get("company_name", symbol)
        data_context = json.dumps(analysis_data, indent=2, ensure_ascii=False)

        logger.info(f"ğŸš€ [LLM] {company_name} ({symbol}) ë¶„ì„ ì‹œì‘...")
        try:
            message = await self.client.messages.create(
                model="claude-sonnet-4-5",
                max_tokens=2048,  
                temperature=0.3,    
                system=RESEARCH_REPORT_PROMPT,
                messages=[
                    {
                        "role": "user",
                        "content": f"ë‹¤ìŒ ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ {company_name} ({symbol}) ì¢…ëª©ì— ëŒ€í•œ ê¸°ê´€íˆ¬ìììš© ë¦¬ì„œì¹˜ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì‹­ì‹œì˜¤. ì ˆëŒ€ë¡œ ì‘ë‹µì´ ì¤‘ê°„ì— ëŠì–´ì§€ì§€ ì•Šë„ë¡ JSON í˜•ì‹ì„ ì—„ê²©íˆ ì¤€ìˆ˜í•˜ì‹­ì‹œì˜¤.\n\n[ë°ì´í„°]\n{data_context}"
                    }
                ]
            )
            response_text = message.content[0].text
            logger.info(f"âœ… [LLM] ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ (ê¸¸ì´: {len(response_text)})")

            # JSON íŒŒì‹±
            try:
                # ê°€ì¥ ë°”ê¹¥ìª½ì˜ { } ë¸”ë¡ì„ ì°¾ìŒ
                start_idx = response_text.find('{')
                end_idx = response_text.rfind('}')
                
                if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
                    json_str = response_text[start_idx:end_idx+1].strip()
                else:
                    json_str = response_text
                
                # íŒŒì‹± ì‹œë„
                try:
                    llm_output = json.loads(json_str)
                except json.JSONDecodeError:
                    # ì ˆë‹¨ëœ JSON ë³µêµ¬ ì‹œë„: ë§ˆì§€ë§‰ ì™„ì „í•œ í•„ë“œê¹Œì§€ë§Œ íŒŒì‹±
                    logger.warning("âš ï¸ [LLM] JSON ì ˆë‹¨ ê°ì§€, ë³µêµ¬ ì‹œë„ ì¤‘...")
                    
                    # ë§ˆì§€ë§‰ ì™„ì „í•œ "key": "value" ìŒ ì´í›„ë¡œ ìë¥´ê¸°
                    last_quote = json_str.rfind('"')
                    if last_quote > 0:
                        # ë§ˆì§€ë§‰ ë”°ì˜´í‘œ ì´ì „ì˜ ë§ˆì§€ë§‰ ì½¤ë§ˆ ë˜ëŠ” ì¤‘ê´„í˜¸ ì°¾ê¸°
                        search_area = json_str[:last_quote]
                        last_comma = search_area.rfind(',')
                        
                        if last_comma > 0:
                            # ë§ˆì§€ë§‰ ì½¤ë§ˆê¹Œì§€ ìë¥´ê³  ë‹«ëŠ” ì¤‘ê´„í˜¸ ì¶”ê°€
                            recovered_json = json_str[:last_comma] + '}'
                            llm_output = json.loads(recovered_json)
                            logger.info("âœ… [LLM] ì ˆë‹¨ëœ JSON ë³µêµ¬ ì„±ê³µ")
                        else:
                            raise  # ë³µêµ¬ ë¶ˆê°€ëŠ¥, ì›ë˜ ì—ëŸ¬ ë°œìƒ
                    else:
                        raise  # ë³µêµ¬ ë¶ˆê°€ëŠ¥

                logger.info(f"âœ¨ [LLM] JSON íŒŒì‹± ë° ë°ì´í„° êµ¬ì¡°í™” ì„±ê³µ")

                # ë¬¸ìì—´ í•„ë“œ ì •ë¦¬
                for key in ['key_thesis', 'primary_risk']:
                    if key in llm_output and isinstance(llm_output[key], str):
                        llm_output[key] = llm_output[key].replace('\n', ' ').strip()
                
                # ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ëŠ” ì´ì œ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì¡°ë¦½í•˜ë¯€ë¡œ ë°±ì—”ë“œì—ì„œëŠ” ìƒì„±í•˜ì§€ ì•ŠìŒ
                if "report_markdown" in llm_output:
                    del llm_output["report_markdown"]
                if "conclusion" in llm_output:
                    del llm_output["conclusion"]

                # ë””ë²„ê·¸ ì •ë³´ ì¶”ê°€
                llm_output["_debug"] = {
                    "full_prompt": f"System: {RESEARCH_REPORT_PROMPT}\n\nUser: {company_name} ({symbol}) ë°ì´í„° ë¶„ì„ ìš”ì²­",
                    "raw_data_sent": analysis_data,
                    "raw_response": response_text
                }
                
                # ì„±ê³µ í”Œë˜ê·¸ ì¶”ê°€
                llm_output["is_success"] = True

                return llm_output
                
            except json.JSONDecodeError as e:
                logger.error(f"âŒ JSON íŒŒì‹± ì—ëŸ¬: {e}")
                logger.error(f"ğŸ“„ ì›ë³¸ ì‘ë‹µ í…ìŠ¤íŠ¸: {response_text}")
            
        except Exception as e:
            logger.error(f"âŒ LLM í˜¸ì¶œ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {type(e).__name__} - {e}")
            import traceback
            traceback.print_exc()

        
        # ê¸°ë³¸ ì‘ë‹µ (íŒŒì‹± ì‹¤íŒ¨ ë˜ëŠ” ì˜ˆì™¸ ë°œìƒ ì‹œ)
        return {
            "investment_rating": "ë°ì´í„° ë¶„ì„ ì œí•œ",
            "current_price": 0,
            "key_thesis": "ë°ì´í„° ìˆ˜ì§‘ ë¶€ì¡± ë˜ëŠ” ë¶„ì„ ì˜¤ë¥˜",
            "primary_risk": "ë¦¬ìŠ¤í¬ ì‚°ì¶œ ë¶ˆê°€",
            "is_success": False
        }

llm_service = LLMService()
