import anthropic
import json
from core.config import settings

RESEARCH_REPORT_PROMPT = """
ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ ê¸ˆìœµ ìì‚° ë¶„ì„ê°€(Senior Equity Analyst)ì…ë‹ˆë‹¤.
**ì˜¤ì§ ì œê³µëœ ë°ì´í„°**ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ë¦¬ì„œì¹˜ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì‹­ì‹œì˜¤. 

## [ì ˆëŒ€ ì¤€ìˆ˜ ë²•ì¹™] (í™˜ê° ë° ì´ëª¨ì§€ ì‚¬ìš© ê¸ˆì§€)
- **ì‘ë‹µ ë³¸ë¬¸ì— ì´ëª¨ì§€ë¥¼ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.** (ì˜ˆ: ğŸ“Š, ğŸš€, âœ… ë“± ì‚¬ìš© ê¸ˆì§€)
- **ì œê³µë˜ì§€ ì•Šì€ ì™¸ë¶€ ë‰´ìŠ¤ë‚˜ ì‚¬ì‹¤ì„ ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.** (ì˜ˆ: 'HBM3E', 'ì„¤ë¹„íˆ¬ì', 'ìˆ˜ìœ¨ ê°œì„ ', 'NVDA ê³µê¸‰' ë“± ë°ì´í„°ì— ëª…ì‹œë˜ì§€ ì•Šì€ êµ¬ì²´ì  ê²½ì˜ ë‰´ìŠ¤ ê¸ˆì§€)
- ì˜¤ì§ ì œê³µëœ JSON ë°ì´í„° ë‚´ì˜ ìˆ˜ì¹˜ì™€ ì°¨íŠ¸ì˜ ì‹œê°ì  ìš”ì†Œ(x, yì¶• íë¦„)ì—ë§Œ ì§‘ì¤‘í•˜ì‹­ì‹œì˜¤.
- ì•Œ ìˆ˜ ì—†ëŠ” ë°ì´í„°(ì˜ˆ: P/B ë¯¸ì œê³µ ë“±)ëŠ” ì„ì˜ë¡œ ì¶”ì¸¡í•˜ì§€ ë§ê³  ì–¸ê¸‰ì„ í”¼í•˜ì‹­ì‹œì˜¤.

- **ë¶„ëŸ‰**: ì „ì²´ JSON ì‘ë‹µì˜ í…ìŠ¤íŠ¸ ì´í•©ì´ **í•œê¸€ ê¸°ì¤€ ì•½ 1200~1300ì** ë‚´ì™¸ê°€ ë˜ë„ë¡ í•µì‹¬ ìœ„ì£¼ë¡œ ì••ì¶•í•˜ì—¬ ì„œìˆ í•˜ì‹­ì‹œì˜¤.
- **ì–¸ì–´**: í•œêµ­ì–´

## ì„¹ì…˜ë³„ ì‘ì„± ì§€ì¹¨ (JSON í•„ë“œëª… ì¤€ìˆ˜)
1. `investment_rating`: 'BUY', 'HOLD', 'REDUCE' ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì‹­ì‹œì˜¤.
2. `executive_summary`: íˆ¬ì ê°œìš”. ì „ì²´ ë°ì´í„°ë¥¼ ì¢…í•©í•˜ì—¬ íˆ¬ìì˜ê²¬ì´ ë„ì¶œëœ í•µì‹¬ ë…¼ë¦¬ë¥¼ **3~4ë¬¸ì¥**ìœ¼ë¡œ ìš”ì•½í•˜ì‹­ì‹œì˜¤.
3. `key_thesis`: í•µì‹¬ ë…¼ê±°. íˆ¬ìì˜ê²¬ì„ ë’·ë°›ì¹¨í•˜ëŠ” ê°€ì¥ ê°•ë ¥í•œ ê¸ì •ì  ìš”ì¸ì„ ì§§ì€ ë¬¸ë‹¨ìœ¼ë¡œ ì„œìˆ í•˜ì‹­ì‹œì˜¤.
4. `primary_risk`: ì£¼ìš” ë¦¬ìŠ¤í¬. íˆ¬ì ì‹œ ê°€ì¥ ê²½ê³„í•´ì•¼ í•  ë¶€ì •ì  ìš”ì¸ì„ ì§§ì€ ë¬¸ë‹¨ìœ¼ë¡œ ì„œìˆ í•˜ì‹­ì‹œì˜¤.
5. `fundamental_analysis`: í€ë”ë©˜í„¸ ë¶„ì„. ë§¤ì¶œ/ì˜ì—…ì´ìµ ì¶”ì„¸ ì°¨íŠ¸ì˜ ì£¼ìš” ìˆ˜ì¹˜ì™€ ë³€ê³¡ì ì„ ì„¤ëª…í•˜ì‹­ì‹œì˜¤.
6. `valuation_analysis`: ë°¸ë¥˜ì—ì´ì…˜ ë¶„ì„. PEG/ROE/ìœ ë™ë¹„ìœ¨ì˜ í˜„ì¬ ìƒíƒœë¥¼ ì „ë¬¸ì ìœ¼ë¡œ í‰ê°€í•˜ì‹­ì‹œì˜¤.
7. `technical_analysis`: ê¸°ìˆ ì  ì§€í‘œ ë¶„ì„. RSIì™€ ì´ë™í‰ê· ì„ (200ì¼/300ì¼) ê¸°ë°˜ì˜ ë§¤ë§¤ ì‹¬ë¦¬ì™€ ì¶”ì„¸ë¥¼ ë¶„ì„í•˜ì‹­ì‹œì˜¤.
8. `risk_analysis`: AI ë¦¬ìŠ¤í¬ ì§„ë‹¨. MDDì™€ ë³€ë™ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ í†µê³„ì  ì†ì‹¤ ìœ„í—˜ì„ ì œì‹œí•˜ì‹­ì‹œì˜¤.

## ì¤‘ìš” ê·œì¹™
- ê° ì„¹ì…˜ì€ ë…ë¦½ì ì¸ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•˜ë˜, ë¬¸ì¥ ê°„ì˜ ë…¼ë¦¬ì  ì—°ê²°ì„ ê°•í™”í•˜ì‹­ì‹œì˜¤.
- **ë„ì–´ì“°ê¸°ë¥¼ ì² ì €íˆ í•˜ë©°, ë‹¨ì–´ ì¤‘ê°„ì— ì˜¤íƒ€ì„± ê³µë°±ì´ ìƒê¸°ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜ì‹­ì‹œì˜¤.**
"""

import logging
logger = logging.getLogger(__name__)

class LLMService:
    def __init__(self):
        self.client = anthropic.AsyncAnthropic(api_key=settings.ANTHROPIC_API_KEY)

    async def generate_report(self, analysis_data: dict) -> dict:
        symbol = analysis_data.get("symbol")
        company_name = analysis_data.get("company_name", symbol)
        data_context = json.dumps(analysis_data, indent=2, ensure_ascii=False)

        logger.info(f"[LLM] {company_name} ({symbol}) ë¶„ì„ ì‹œì‘...")
        try:
            message = await self.client.messages.create(
                model="claude-sonnet-4-5",
                max_tokens=3000,  # ë¶„ëŸ‰ ìµœì í™” (ê¸°ì¡´ ëŒ€ë¹„ 2/3 ìˆ˜ì¤€)
                temperature=0.3,    
                system=RESEARCH_REPORT_PROMPT,
                messages=[
                    {
                        "role": "user",
                        "content": f"ë‹¤ìŒ ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ {company_name} ({symbol}) ì¢…ëª©ì— ëŒ€í•œ ê¸°ê´€íˆ¬ìììš© ë¦¬ì„œì¹˜ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì‹­ì‹œì˜¤. ì ˆëŒ€ë¡œ ì‘ë‹µì´ ì¤‘ê°„ì— ëŠì–´ì§€ì§€ ì•Šë„ë¡ JSON í˜•ì‹ì„ ì—„ê²©íˆ ì¤€ìˆ˜í•˜ì‹­ì‹œì˜¤.\n\n[ë°ì´í„°]\n{data_context}"
                    }
                ]
            )
            response_text = message.content[0].text
            logger.info(f"[LLM] ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ (ê¸¸ì´: {len(response_text)})")

            # JSON íŒŒì‹±
            try:
                # ê°€ì¥ ë°”ê¹¥ìª½ì˜ { } ë¸”ë¡ì„ ì°¾ìŒ
                start_idx = response_text.find('{')
                end_idx = response_text.rfind('}')
                
                if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
                    json_str = response_text[start_idx:end_idx+1].strip()
                else:
                    json_str = response_text
                
                # íŒŒì‹± ì‹œë„
                try:
                    llm_output = json.loads(json_str)
                except json.JSONDecodeError:
                    # ì ˆë‹¨ëœ JSON ë³µêµ¬ ì‹œë„: ë§ˆì§€ë§‰ ì™„ì „í•œ í•„ë“œê¹Œì§€ë§Œ íŒŒì‹±
                    logger.warning("[LLM] JSON ì ˆë‹¨ ê°ì§€, ë³µêµ¬ ì‹œë„ ì¤‘...")
                    
                    # ë§ˆì§€ë§‰ ì™„ì „í•œ "key": "value" ìŒ ì´í›„ë¡œ ìë¥´ê¸°
                    last_quote = json_str.rfind('"')
                    if last_quote > 0:
                        # ë§ˆì§€ë§‰ ë”°ì˜´í‘œ ì´ì „ì˜ ë§ˆì§€ë§‰ ì½¤ë§ˆ ë˜ëŠ” ì¤‘ê´„í˜¸ ì°¾ê¸°
                        search_area = json_str[:last_quote]
                        last_comma = search_area.rfind(',')
                        
                        if last_comma > 0:
                            # ë§ˆì§€ë§‰ ì½¤ë§ˆê¹Œì§€ ìë¥´ê³  ë‹«ëŠ” ì¤‘ê´„í˜¸ ì¶”ê°€
                            recovered_json = json_str[:last_comma] + '}'
                            llm_output = json.loads(recovered_json)
                            logger.info("[LLM] ì ˆë‹¨ëœ JSON ë³µêµ¬ ì„±ê³µ")
                        else:
                            raise  # ë³µêµ¬ ë¶ˆê°€ëŠ¥, ì›ë˜ ì—ëŸ¬ ë°œìƒ
                    else:
                        raise  # ë³µêµ¬ ë¶ˆê°€ëŠ¥

                logger.info(f"[LLM] JSON íŒŒì‹± ë° ë°ì´í„° êµ¬ì¡°í™” ì„±ê³µ")

                # ë¬¸ìì—´ í•„ë“œ ì •ë¦¬
                for key in ['key_thesis', 'primary_risk']:
                    if key in llm_output and isinstance(llm_output[key], str):
                        llm_output[key] = llm_output[key].replace('\n', ' ').strip()
                
                # ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ëŠ” ì´ì œ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì¡°ë¦½í•˜ë¯€ë¡œ ë°±ì—”ë“œì—ì„œëŠ” ìƒì„±í•˜ì§€ ì•ŠìŒ
                if "report_markdown" in llm_output:
                    del llm_output["report_markdown"]
                if "conclusion" in llm_output:
                    del llm_output["conclusion"]

                # ë””ë²„ê·¸ ì •ë³´ ì¶”ê°€
                llm_output["_debug"] = {
                    "full_prompt": f"System: {RESEARCH_REPORT_PROMPT}\n\nUser: {company_name} ({symbol}) ë°ì´í„° ë¶„ì„ ìš”ì²­",
                    "raw_data_sent": analysis_data,
                    "raw_response": response_text
                }
                
                # ì„±ê³µ í”Œë˜ê·¸ ì¶”ê°€
                llm_output["is_success"] = True

                return llm_output
                
            except json.JSONDecodeError as e:
                logger.error(f"âŒ JSON íŒŒì‹± ì—ëŸ¬: {e}")
                logger.error(f"ğŸ“„ ì›ë³¸ ì‘ë‹µ í…ìŠ¤íŠ¸: {response_text}")
            
        except Exception as e:
            logger.error(f"âŒ LLM í˜¸ì¶œ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {type(e).__name__} - {e}")
            import traceback
            traceback.print_exc()

        
        # ê¸°ë³¸ ì‘ë‹µ (íŒŒì‹± ì‹¤íŒ¨ ë˜ëŠ” ì˜ˆì™¸ ë°œìƒ ì‹œ)
        return {
            "investment_rating": "ë°ì´í„° ë¶„ì„ ì œí•œ",
            "current_price": 0,
            "key_thesis": "ë°ì´í„° ìˆ˜ì§‘ ë¶€ì¡± ë˜ëŠ” ë¶„ì„ ì˜¤ë¥˜",
            "primary_risk": "ë¦¬ìŠ¤í¬ ì‚°ì¶œ ë¶ˆê°€",
            "is_success": False
        }

llm_service = LLMService()
